{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "descending-gender",
   "metadata": {},
   "source": [
    "# Глава 5. Корректировка сразу нескольких весов. Обобщение градиентного спуска"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-eagle",
   "metadata": {},
   "source": [
    "## Пример  градиентного спуска для простой нейронной сети с тремя входами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "tough-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция нейросети\n",
    "def neural_network(input, weight):\n",
    "    assert(len(input) == len(weight))\n",
    "    out = 0\n",
    "    for i in range(len(input)):\n",
    "        out += input[i] * weight[i]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "hispanic-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция калибровки веса\n",
    "#Каждый input домножается на delta для подгонки веса в нужную сторону с нужным масштабом (Градиентный спуск)\n",
    "def calibration(input_vector, delta):\n",
    "\n",
    "    out = [0,0,0]\n",
    "    for i in range(len(input_vector)):\n",
    "        out[i] = input_vector[i] * delta\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "activated-mustang",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Задаём начальные данные\n",
    "toes = [8.5]\n",
    "winrate = [0.65]\n",
    "fans = [1.2]\n",
    "goal_pred = [1]\n",
    "true = goal_pred[0] #TODO: Разобраться почему это нужно. Если в цикле ошибку вычислять как pred - goal_pred,\n",
    "alpha = 0.01       #то выдаст ошибку\n",
    "weights = [0.1, 0.2, -.1]\n",
    "input = [toes[0], winrate[0],fans[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "electrical-acting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\tPrediction: 0.8600000000000001\n",
      "Iteration: 1\tPrediction: 0.9637574999999999\n",
      "Iteration: 2\tPrediction: 0.9906177228125002\n",
      "Iteration: 3\tPrediction: 0.997571162993086\n",
      "Iteration: 4\tPrediction: 0.9993712348198351\n",
      "Iteration: 5\tPrediction: 0.9998372284139849\n",
      "Iteration: 6\tPrediction: 0.9999578625056702\n",
      "Iteration: 7\tPrediction: 0.9999890916561555\n",
      "Iteration: 8\tPrediction: 0.9999971761024872\n",
      "Iteration: 9\tPrediction: 0.9999992689635313\n",
      "Iteration: 10\tPrediction: 0.9999998107529342\n",
      "Iteration: 11\tPrediction: 0.9999999510086658\n",
      "Iteration: 12\tPrediction: 0.9999999873173683\n",
      "Iteration: 13\tPrediction: 0.9999999967167837\n",
      "Iteration: 14\tPrediction: 0.9999999991500574\n",
      "Iteration: 15\tPrediction: 0.999999999779971\n",
      "Iteration: 16\tPrediction: 0.9999999999430399\n",
      "Iteration: 17\tPrediction: 0.9999999999852546\n",
      "Iteration: 18\tPrediction: 0.9999999999961828\n",
      "Iteration: 19\tPrediction: 0.999999999999012\n",
      "Iteration: 20\tPrediction: 0.9999999999997441\n",
      "Iteration: 21\tPrediction: 0.9999999999999336\n",
      "Iteration: 22\tPrediction: 0.999999999999983\n",
      "Iteration: 23\tPrediction: 0.9999999999999954\n",
      "Iteration: 24\tPrediction: 0.9999999999999989\n",
      "Iteration: 25\tPrediction: 0.9999999999999998\n",
      "Iteration: 26\tPrediction: 0.9999999999999998\n",
      "Iteration: 27\tPrediction: 1.0\n",
      "Stop!\n"
     ]
    }
   ],
   "source": [
    "#Цикл\n",
    "for i in range(40):\n",
    "    pred = neural_network(input, weights) #Возвращает одно значение типа float - наше предсказание\n",
    "    print(\"Iteration: \" + str(i) + \"\\tPrediction: \" + str(pred))\n",
    "    error = (pred - true)**2\n",
    "    delta = pred - true\n",
    "    weights_deltas = calibration(input, delta) #Изменяем каждый вес\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] -= weights_deltas[i] * alpha  #Домножаем на альфа, чтобы при оч. больших input не было проблем\n",
    "    if pred == true: #Если прогноз достигнут, то останавливаемся\n",
    "        print(\"Stop!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-forty",
   "metadata": {},
   "source": [
    "## При градиентеном спуске с несколькими входами возникает проблема, если один из входов намного больше остальных. Для решения данной проблемы необходимо выбирать более маленький по значению альфа-коэффициент или, ещё лучше, стандартизировать данные, чтобы сделать обучение более равномерным по всем весам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-archive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "secret-circular",
   "metadata": {},
   "source": [
    "## Замораживание одного веса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "entitled-customer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция нейросети\n",
    "def neural_network(input, weight):\n",
    "    assert(len(input) == len(weight))\n",
    "    out = 0\n",
    "    for i in range(len(input)):\n",
    "        out += input[i] * weight[i]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "brave-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция калибровки веса\n",
    "#Каждый input домножается на delta для подгонки веса в нужную сторону с нужным масштабом (Градиентный спуск)\n",
    "def calibration(input_vector, delta):\n",
    "\n",
    "    out = [0,0,0]\n",
    "    for i in range(len(input_vector)):\n",
    "        out[i] = input_vector[i] * delta\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "superb-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Задаём начальные данные\n",
    "toes = [8.5]\n",
    "winrate = [0.65]\n",
    "fans = [1.2]\n",
    "goal_pred = [1]\n",
    "true = goal_pred[0] #TODO: Разобраться почему это нужно. Если в цикле ошибку вычислять как pred - goal_pred,\n",
    "alpha = 0.01       #то выдаст ошибку\n",
    "weights = [0.1, 0.2, -.1]\n",
    "input = [toes[0], winrate[0],fans[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "chronic-purse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\tPrediction: 0.8600000000000001\n",
      "[0, -0.09099999999999994, -0.16799999999999987]\n",
      "Iteration: 1\tPrediction: 0.8626075000000001\n",
      "[0, -0.08930512499999994, -0.1648709999999999]\n",
      "Iteration: 2\tPrediction: 0.8651664353125001\n",
      "[0, -0.0876418170468749, -0.16180027762499982]\n",
      "Iteration: 3\tPrediction: 0.8676777104548048\n",
      "[0, -0.08600948820437689, -0.15878674745423424]\n",
      "Iteration: 4\tPrediction: 0.870142213097584\n",
      "[0, -0.0844075614865704, -0.1558293442828992]\n",
      "Iteration: 5\tPrediction: 0.8725608143786415\n",
      "[0, -0.08283547065388301, -0.15292702274563016]\n",
      "Iteration: 6\tPrediction: 0.8749343692108393\n",
      "[0, -0.08129266001295443, -0.1500787569469928]\n",
      "Iteration: 7\tPrediction: 0.8772637165842875\n",
      "[0, -0.07977858422021314, -0.14728354009885503]\n",
      "Iteration: 8\tPrediction: 0.8795496798629052\n",
      "[0, -0.07829270808911161, -0.14454038416451373]\n",
      "Iteration: 9\tPrediction: 0.8817930670754586\n",
      "[0, -0.07683450640095194, -0.1418483195094497]\n",
      "Iteration: 10\tPrediction: 0.8839946712011781\n",
      "[0, -0.07540346371923422, -0.13920639455858622]\n",
      "Iteration: 11\tPrediction: 0.8861552704500562\n",
      "[0, -0.0739990742074635, -0.1366136754599326]\n",
      "Iteration: 12\tPrediction: 0.888275628537924\n",
      "[0, -0.07262084145034943, -0.13406924575449122]\n",
      "Iteration: 13\tPrediction: 0.890356494956405\n",
      "[0, -0.07126827827833675, -0.13157220605231398]\n",
      "Iteration: 14\tPrediction: 0.8923986052378421\n",
      "[0, -0.06994090659540264, -0.1291216737145895]\n",
      "Iteration: 15\tPrediction: 0.8944026812152872\n",
      "[0, -0.06863825721006332, -0.12671678254165533]\n",
      "Iteration: 16\tPrediction: 0.8963694312776525\n",
      "[0, -0.06735986966952591, -0.12435668246681705]\n",
      "Iteration: 17\tPrediction: 0.8982995506201062\n",
      "[0, -0.06610529209693095, -0.1220405392558725]\n",
      "Iteration: 18\tPrediction: 0.9001937214898067\n",
      "[0, -0.06487408103162565, -0.11976753421223196]\n",
      "Iteration: 19\tPrediction: 0.9020526134270591\n",
      "[0, -0.06366580127241157, -0.11753686388752906]\n",
      "Iteration: 20\tPrediction: 0.90387688350198\n",
      "[0, -0.06248002572371298, -0.11534773979762396]\n",
      "Iteration: 21\tPrediction: 0.9056671765467558\n",
      "[0, -0.06131633524460875, -0.11319938814389308]\n",
      "Iteration: 22\tPrediction: 0.9074241253835724\n",
      "[0, -0.06017431850067793, -0.11109104953971309]\n",
      "Iteration: 23\tPrediction: 0.9091483510483034\n",
      "[0, -0.0590535718186028, -0.10902197874203594]\n",
      "Iteration: 24\tPrediction: 0.9108404630100286\n",
      "[0, -0.05795369904348139, -0.10699144438796564]\n",
      "Iteration: 25\tPrediction: 0.912501059386467\n",
      "[0, -0.05687431139879647, -0.10499872873623962]\n",
      "Iteration: 26\tPrediction: 0.914130727155394\n",
      "[0, -0.0558150273489939, -0.10304312741352718]\n",
      "Iteration: 27\tPrediction: 0.9157300423621247\n",
      "[0, -0.05477547246461892, -0.10112394916545031]\n",
      "Iteration: 28\tPrediction: 0.9172995703231301\n",
      "[0, -0.05375527928996541, -0.09924051561224383]\n",
      "Iteration: 29\tPrediction: 0.918839865825862\n",
      "[0, -0.05275408721318972, -0.09739216100896564]\n",
      "Iteration: 30\tPrediction: 0.9203514733248552\n",
      "[0, -0.0517715423388441, -0.09557823201017372]\n",
      "Iteration: 31\tPrediction: 0.9218349271341798\n",
      "[0, -0.05080729736278313, -0.09379808743898423]\n",
      "Iteration: 32\tPrediction: 0.9232907516163057\n",
      "[0, -0.0498610114494013, -0.09205109806043317]\n",
      "Iteration: 33\tPrediction: 0.9247194613674519\n",
      "[0, -0.048932350111156285, -0.09033664635905776]\n",
      "Iteration: 34\tPrediction: 0.9261215613994832\n",
      "[0, -0.048020985090335915, -0.08865412632062016]\n",
      "Iteration: 35\tPrediction: 0.9274975473184179\n",
      "[0, -0.04712659424302834, -0.08700294321789848]\n",
      "Iteration: 36\tPrediction: 0.9288479054996123\n",
      "[0, -0.04624886142525202, -0.08538251340046528]\n",
      "Iteration: 37\tPrediction: 0.930173113259682\n",
      "[0, -0.04538747638120671, -0.0837922640883816]\n",
      "Iteration: 38\tPrediction: 0.9314736390252204\n",
      "[0, -0.04454213463360674, -0.08223163316973552]\n",
      "Iteration: 39\tPrediction: 0.9327499424983757\n",
      "[0, -0.04371253737605578, -0.08070006900194912]\n",
      "Iteration: 40\tPrediction: 0.9340024748193435\n",
      "[0, -0.04289839136742672, -0.07919703021678778]\n",
      "Iteration: 41\tPrediction: 0.9352316787258332\n",
      "[0, -0.042099408828208396, -0.07772198552900011]\n",
      "Iteration: 42\tPrediction: 0.9364379887095645\n",
      "[0, -0.04131530733878307, -0.07627441354852257]\n",
      "Iteration: 43\tPrediction: 0.9376218311698489\n",
      "[0, -0.04054580973959823, -0.07485380259618135]\n",
      "Iteration: 44\tPrediction: 0.9387836245643104\n",
      "[0, -0.03979064403319823, -0.0734596505228275]\n",
      "Iteration: 45\tPrediction: 0.9399237795568002\n",
      "[0, -0.039049543288079885, -0.07209146453183979]\n",
      "Iteration: 46\tPrediction: 0.9410426991625548\n",
      "[0, -0.03832224554433939, -0.07074876100493425]\n",
      "Iteration: 47\tPrediction: 0.9421407788906522\n",
      "[0, -0.03760849372107609, -0.06943106533121739]\n",
      "Iteration: 48\tPrediction: 0.9432184068838138\n",
      "[0, -0.03690803552552106, -0.06813791173942349]\n",
      "Iteration: 49\tPrediction: 0.9442759640556028\n",
      "[0, -0.0362206233638582, -0.06686884313327668]\n",
      "Iteration: 50\tPrediction: 0.9453138242250672\n",
      "[0, -0.03554601425370635, -0.06562341092991941]\n",
      "Iteration: 51\tPrediction: 0.9463323542488752\n",
      "[0, -0.03488396973823113, -0.06440117490134978]\n",
      "Iteration: 52\tPrediction: 0.9473319141509899\n",
      "[0, -0.03423425580185654, -0.06320170301881207]\n",
      "Iteration: 53\tPrediction: 0.9483128572499279\n",
      "[0, -0.03359664278754689, -0.06202457130008656]\n",
      "Iteration: 54\tPrediction: 0.949275530283648\n",
      "[0, -0.032970905315628816, -0.06086936365962243]\n",
      "Iteration: 55\tPrediction: 0.950220273532115\n",
      "[0, -0.03235682220412524, -0.05973567176146197]\n",
      "Iteration: 56\tPrediction: 0.9511474209375794\n",
      "[0, -0.031754176390573374, -0.05862309487490469]\n",
      "Iteration: 57\tPrediction: 0.9520573002226169\n",
      "[0, -0.031162754855299003, -0.057531239732859694]\n",
      "Iteration: 58\tPrediction: 0.9529502330059706\n",
      "[0, -0.030582348546119117, -0.05645972039283528]\n",
      "Iteration: 59\tPrediction: 0.9538265349162345\n",
      "[0, -0.03001275230444759, -0.05540815810051862]\n",
      "Iteration: 60\tPrediction: 0.9546865157034196\n",
      "[0, -0.02945376479277729, -0.05437618115589653]\n",
      "Iteration: 61\tPrediction: 0.9555304793484434\n",
      "[0, -0.028905188423511807, -0.05336342478186795]\n",
      "Iteration: 62\tPrediction: 0.9563587241705787\n",
      "[0, -0.028366829289123874, -0.05236953099530561]\n",
      "Iteration: 63\tPrediction: 0.9571715429329015\n",
      "[0, -0.027838497093614013, -0.051394148480518174]\n",
      "Iteration: 64\tPrediction: 0.9579692229457762\n",
      "[0, -0.02732000508524544, -0.05043693246506851]\n",
      "Iteration: 65\tPrediction: 0.9587520461684113\n",
      "[0, -0.026811169990532686, -0.04949754459790649]\n",
      "Iteration: 66\tPrediction: 0.9595202893085244\n",
      "[0, -0.02631181194945914, -0.04857565282977072]\n",
      "Iteration: 67\tPrediction: 0.9602742239201533\n",
      "[0, -0.025821754451900377, -0.04767093129581607]\n",
      "Iteration: 68\tPrediction: 0.9610141164996404\n",
      "[0, -0.025340824275233733, -0.0467830602004315]\n",
      "Iteration: 69\tPrediction: 0.9617402285798344\n",
      "[0, -0.02486885142310762, -0.04591172570419868]\n",
      "Iteration: 70\tPrediction: 0.9624528168225351\n",
      "[0, -0.02440566906535216, -0.04505661981295783]\n",
      "Iteration: 71\tPrediction: 0.9631521331092154\n",
      "[0, -0.023951113479009967, -0.04421744026894148]\n",
      "Iteration: 72\tPrediction: 0.9638384246300564\n",
      "[0, -0.023505023990463326, -0.04339389044393229]\n",
      "Iteration: 73\tPrediction: 0.9645119339713216\n",
      "[0, -0.023067242918640946, -0.04258567923441405]\n",
      "Iteration: 74\tPrediction: 0.9651728992011056\n",
      "[0, -0.022637615519281357, -0.04179252095867327]\n",
      "Iteration: 75\tPrediction: 0.965821553953485\n",
      "[0, -0.022215989930234742, -0.041014135255817985]\n",
      "Iteration: 76\tPrediction: 0.9664581275111015\n",
      "[0, -0.021802217117784028, -0.04025024698667821]\n",
      "Iteration: 77\tPrediction: 0.9670828448862071\n",
      "[0, -0.02139615082396538, -0.039500586136551476]\n",
      "Iteration: 78\tPrediction: 0.9676959269002015\n",
      "[0, -0.020997647514869055, -0.03876488771975826]\n",
      "Iteration: 79\tPrediction: 0.9682975902616854\n",
      "[0, -0.020606566329904503, -0.03804289168597754]\n",
      "Iteration: 80\tPrediction: 0.9688880476430615\n",
      "[0, -0.020222769032010045, -0.03733434282832624]\n",
      "Iteration: 81\tPrediction: 0.9694675077557094\n",
      "[0, -0.01984611995878886, -0.03663899069314867]\n",
      "Iteration: 82\tPrediction: 0.9700361754237592\n",
      "[0, -0.019476485974556524, -0.035956589491488965]\n",
      "Iteration: 83\tPrediction: 0.9705942516564917\n",
      "[0, -0.019113736423280386, -0.035286898012209945]\n",
      "Iteration: 84\tPrediction: 0.9711419337193896\n",
      "[0, -0.01875774308239675, -0.03462967953673246]\n",
      "Iteration: 85\tPrediction: 0.9716794152038659\n",
      "[0, -0.018408380117487157, -0.0339847017553609]\n",
      "Iteration: 86\tPrediction: 0.9722068860956941\n",
      "[0, -0.018065524037798864, -0.03335173668516713]\n",
      "Iteration: 87\tPrediction: 0.9727245328421615\n",
      "[0, -0.017729053652595, -0.032730560589406155]\n",
      "Iteration: 88\tPrediction: 0.9732325384179764\n",
      "[0, -0.017398850028315333, -0.032120953898428305]\n",
      "Iteration: 89\tPrediction: 0.9737310823899415\n",
      "[0, -0.017074796446537994, -0.03152270113207014]\n",
      "Iteration: 90\tPrediction: 0.9742203409804288\n",
      "[0, -0.016756778362721308, -0.03093559082348549]\n",
      "Iteration: 91\tPrediction: 0.9747004871296684\n",
      "[0, -0.016444683365715546, -0.03035941544439793]\n",
      "Iteration: 92\tPrediction: 0.9751716905568784\n",
      "[0, -0.016138401138029067, -0.02979397133174597]\n",
      "Iteration: 93\tPrediction: 0.9756341178202564\n",
      "[0, -0.015837823416833315, -0.02923905861569227]\n",
      "Iteration: 94\tPrediction: 0.9760879323758542\n",
      "[0, -0.015542843955694753, -0.028694481148974924]\n",
      "Iteration: 95\tPrediction: 0.9765332946353539\n",
      "[0, -0.015253358487019981, -0.028160046437575345]\n",
      "Iteration: 96\tPrediction: 0.9769703620227704\n",
      "[0, -0.014969264685199218, -0.02763556557267548]\n",
      "Iteration: 97\tPrediction: 0.9773992890300964\n",
      "[0, -0.01469046213043732, -0.027120853163884285]\n",
      "Iteration: 98\tPrediction: 0.977820227271911\n",
      "[0, -0.014416852273257863, -0.026615727273706823]\n",
      "Iteration: 99\tPrediction: 0.9782333255389714\n",
      "[0, -0.01414833839966862, -0.026120009353234375]\n"
     ]
    }
   ],
   "source": [
    "#Цикл\n",
    "for i in range(100):\n",
    "    pred = neural_network(input, weights) #Возвращает одно значение типа float - наше предсказание\n",
    "    print(\"Iteration: \" + str(i) + \"\\tPrediction: \" + str(pred))\n",
    "    error = (pred - true)**2\n",
    "    delta = pred - true\n",
    "    weights_deltas = calibration(input, delta) #Изменяем каждый вес\n",
    "    \n",
    "    \n",
    "    #######################################################\n",
    "    #ПО СРАВНЕНИЮ С ПРОШЛЫМ КОДОМ МЫ ДОБАВЛЯЕМ СТРОКУ НИЖЕ!\n",
    "    weights_deltas[0] = 0 #Мы замораживаем первый, чтобы попытаться дать верный прогноз путем изменения \n",
    "                         #только весов для второго и третьего input\n",
    "                        #Если сеть может дать идеальный прогноз без использования каких-то данных,\n",
    "                       #то это чревато тем, что потом она продолжит игнорировать их, даже если вы снова активируете\n",
    "                      #эти данные для анализа. Ведь зачем их использовать, если  и без них всё идеально?\n",
    "    print(weights_deltas)\n",
    "    #######################################################\n",
    "    \n",
    "    \n",
    "    for i in range(len(weights)):\n",
    "        weights[i] -= weights_deltas[i] * alpha  #Домножаем на альфа, чтобы при оч. больших input не было проблем\n",
    "    if pred == true: #Если прогноз достигнут, то останавливаемся\n",
    "        print(\"Stop!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-cabinet",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "###  Из-за оч. большого значения input[0] подгонять вес для безошибочного прогноза стало очень трудно. Т.к. именно этот input оказывает наибольшее влияние на прогноз, а мы просто перестали учитывать это влияние. Если перестать учитывать 1 или 2 input, то прогноз  отлично вычисляется. Причем при неучете input[1] идеальный прогноз выдается за те же 27 итераций, как и при обычном прогнозе с учетом всех трех переменных, а при неучете input[2] идеальный прогноз достигается за 28 итераций (+1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-thanks",
   "metadata": {},
   "source": [
    "## Обучение методом градиентного спуска с несколькими выходами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "nuclear-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "wr = [0.65]\n",
    "input = wr[0]\n",
    "weights = [0.3, 0.2, 0.9]\n",
    "alpha = 0.1\n",
    "hurt = [0.1]\n",
    "win = [1]\n",
    "sad = [0.1]\n",
    "true = [hurt[0], win[0], sad[0]]\n",
    "def neural_network(input, weights):\n",
    "    pred = elem_multi(input,weights)\n",
    "    return pred\n",
    "\n",
    "def elem_multi(input, weights_vector):\n",
    "    out = [0,0,0]\n",
    "    for i in range(len(weights_vector)):\n",
    "        out[i] = input * weights_vector[i]\n",
    "    return out\n",
    "def calibration(input,delta_vector):\n",
    "    out = [0,0,0]\n",
    "    assert(len(out) == len(delta_vector))\n",
    "    for i in range(len(out)):\n",
    "        out[i] = input * delta_vector[i]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "noticed-baseline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.195, 0.13, 0.5850000000000001]\n",
      "[0.19098625, 0.1667575, 0.56450875]\n",
      "[0.1871420809375, 0.20196199562500003, 0.5448832553125]\n",
      "[0.18346032801789064, 0.23567910130984374, 0.5260869377755468]\n",
      "[0.17993412915913473, 0.26797165927950284, 0.50808476465453]\n",
      "[0.1765569122021613, 0.29889985667494384, 0.4908431833478762]\n",
      "[0.17332238266161998, 0.3285213377304275, 0.4743300588514284]\n",
      "[0.17022451199416655, 0.3568913112113169, 0.45851461386495557]\n",
      "[0.167257526362413, 0.3840626533126388, 0.4433673714291612]\n",
      "[0.16441589587360106, 0.41008600621017977, 0.42886009998627916]\n",
      "[0.16169432427294142, 0.43500987244779965, 0.41496576076185887]\n",
      "[0.15908773907240964, 0.45888070533688013, 0.4016584573696704]\n",
      "[0.15659128209660034, 0.481742995536397, 0.3889133875458018]\n",
      "[0.15420030042801897, 0.5036393539749842, 0.3767067969219916]\n",
      "[0.15191033773493517, 0.5246105912695411, 0.36501593475203753]\n",
      "[0.14971712596563416, 0.544695793788403, 0.3538190115087639]\n",
      "[0.14761657739358613, 0.563932396500843, 0.34309515827251863]\n",
      "[0.1456047769987071, 0.5823562527486824, 0.3328243878355047]\n",
      "[0.14367797517051173, 0.6000017010700506, 0.3229875574494547]\n",
      "[0.14183258071955762, 0.6169016291998409, 0.3135663331472152]\n",
      "[0.1400651541841563, 0.6330875353661476, 0.3045431555717454]\n",
      "[0.1383724014198757, 0.6485895869969279, 0.29590120724883917]\n",
      "[0.13675116745988594, 0.6634366769463077, 0.2876243812425757]\n",
      "[0.13519843063470577, 0.6776564773453263, 0.2796972511350769]\n",
      "[0.13371129694038947, 0.6912754911774862, 0.27210504227461985]\n",
      "[0.132286994644658, 0.7043191016752374, 0.26483360423851715]\n",
      "[0.13092286912092121, 0.7168116196294586, 0.2578693844594398]\n",
      "[0.1296163779005623, 0.728776328700114, 0.2511994029660285]\n",
      "[0.12836508593426352, 0.7402355288125343, 0.2448112281907138]\n",
      "[0.1271666610535409, 0.7512105777202047, 0.23869295379965613]\n",
      "[0.1260188696240288, 0.7617219308115261, 0.23283317650162066]\n",
      "[0.1249195723824136, 0.771789179234739, 0.22722097479442718]\n",
      "[0.12386672044925662, 0.7814310864120713, 0.22184588860936263]\n",
      "[0.12285835151027552, 0.7906656230111612, 0.21669789981561707]\n",
      "[0.12189258615896638, 0.7995100004389396, 0.21176741354840725]\n",
      "[0.12096762439375004, 0.8079807029203945, 0.20704524032598706]\n",
      "[0.1200817422631141, 0.8160935182220079, 0.20252257892221412]\n",
      "[0.11923328865249753, 0.823863567077128, 0.19819099996275058]\n",
      "[0.11842068220692953, 0.8313053313681193, 0.19404243021432435]\n",
      "[0.11764240838368675, 0.8384326811178163, 0.19006913753776916]\n",
      "[0.11689701662947598, 0.8452589003405885, 0.1862637164767984]\n",
      "[0.11618311767688062, 0.8517967118011986, 0.18261907445565365]\n",
      "[0.11549938095503241, 0.858058300727598, 0.17912841855990227]\n",
      "[0.11484453210968229, 0.864055337521857, 0.17578524287574643]\n",
      "[0.11421735062804822, 0.8697989995115585, 0.17258331636424615]\n",
      "[0.11361666756401319, 0.8752999917821952, 0.16951667124785674]\n",
      "[0.11304136335943364, 0.8805685671293975, 0.1665795918876348]\n",
      "[0.11249036575749757, 0.8856145451681804, 0.16376660413038224]\n",
      "[0.11196264780424331, 0.8904473306348247, 0.16107246510587359]\n",
      "[0.11145722593451403, 0.8950759309155034, 0.15849215345515044]\n",
      "[0.11097315813878081, 0.8995089728343234, 0.1560208599716703]\n",
      "[0.11050954220741734, 0.9037547187320731, 0.15365397863786726]\n",
      "[0.11006551404915395, 0.907821081865643, 0.15138709804041736]\n",
      "[0.1096402460805772, 0.9117156411568197, 0.1492159931482097]\n",
      "[0.1092329456836728, 0.915445655317944, 0.14713661743769788]\n",
      "[0.10884285372853762, 0.9190180763807608, 0.14514509535095513]\n",
      "[0.1084692431585069, 0.9224395626536737, 0.1432377150723773]\n",
      "[0.10811141763505999, 0.9257164911315561, 0.14141092161056934]\n",
      "[0.10776871023997871, 0.9288549693812478, 0.13966131017252278]\n",
      "[0.10744048223233961, 0.93186084692489, 0.1379856198177337]\n",
      "[0.10712612185802327, 0.9347397261423134, 0.13638072738043444]\n",
      "[0.10682504320952178, 0.9374969727128006, 0.1348436416486111]\n",
      "[0.10653668513391948, 0.9401377256156848, 0.13337149778895727]\n",
      "[0.10626051018701138, 0.942666906708422, 0.13196155200737383]\n",
      "[0.10599600363161016, 0.9450892298999913, 0.1306111764350623]\n",
      "[0.10574267247817463, 0.9474092099367167, 0.1293178542306809]\n",
      "[0.10550004456597177, 0.9496311708168904, 0.12807917488943465]\n",
      "[0.10526766768305947, 0.9517592538498768, 0.12689282975035604]\n",
      "[0.1050451087234502, 0.9537974253747195, 0.1257566076934035]\n",
      "[0.10483195287988444, 0.9557494841526376, 0.12466839101835718]\n",
      "[0.10462780287070933, 0.9576190684471887, 0.12362615149783159]\n",
      "[0.10443227819942186, 0.959409662805295, 0.1226279465970482]\n",
      "[0.10424501444549628, 0.9611246045517714, 0.12167191585332292]\n",
      "[0.10406566258517405, 0.962767090009459, 0.12075627740852002]\n",
      "[0.10389388834095045, 0.9643401804565594, 0.11987932468801005]\n",
      "[0.1037293715585453, 0.9658468078322697, 0.11903942321994161]\n",
      "[0.10357180561019676, 0.9672897802013565, 0.11823500758889907]\n",
      "[0.10342089682316595, 0.9686717869878492, 0.1174645785182681]\n",
      "[0.10327636393238719, 0.9699954039876125, 0.11672670007587126]\n",
      "[0.10313793755624384, 0.9712630981691359, 0.1160199969976657]\n",
      "[0.10300535969449254, 0.9724772322714899, 0.11534315212451432]\n",
      "[0.10287838324740023, 0.9736400692080195, 0.11469490394725358]\n",
      "[0.10275677155519757, 0.9747537762839806, 0.11407404425548212]\n",
      "[0.10264029795699048, 0.9758204292359826, 0.11347941588568801]\n",
      "[0.10252874536830762, 0.9768420161007622, 0.1129099105645177]\n",
      "[0.10242190587649663, 0.977820440920505, 0.11236446684316682]\n",
      "[0.10231958035321465, 0.9787575272916137, 0.11184206811904303]\n",
      "[0.10222157808329131, 0.9796550217635431, 0.11134174074101347]\n",
      "[0.10212771640927226, 0.9805145970940334, 0.11086255219470564]\n",
      "[0.10203782039098051, 0.9813378553668105, 0.11040360936447934]\n",
      "[0.10195172247946159, 0.9821263309775629, 0.10996405686883008]\n",
      "[0.10186926220470434, 0.9828814934937607, 0.109543075466122]\n",
      "[0.10179028587655559, 0.9836047503936494, 0.10913988052767835]\n",
      "[0.10171464629827111, 0.9842974496895176, 0.10875372057538393]\n",
      "[0.10164220249216917, 0.9849608824401356, 0.10838387588107397]\n",
      "[0.10157281943687502, 0.9855962851570399, 0.1080296571250986]\n",
      "[0.10150636781566705, 0.9862048421091549, 0.10769040411156318]\n",
      "[0.10144272377545512, 0.9867876875300431, 0.10736548453784962]\n",
      "[0.10138176869594213, 0.9873459077318988, 0.10705429281612547]\n",
      "[0.10132338896853857, 0.9878805431302261, 0.10675624894464417]\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    pred = neural_network(input, weights)\n",
    "    print(pred)\n",
    "    error = [0,0,0]\n",
    "    delta = [0,0,0]\n",
    "    assert(len(error) == len(delta))\n",
    "    for i in range(len(error)):\n",
    "        error[i] = (pred[i] - true[i])**2\n",
    "        delta[i] = pred[i] - true[i]\n",
    "    \n",
    "    weights_delta = calibration(input,delta)\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] -= weights_delta[i] * alpha\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-secondary",
   "metadata": {},
   "source": [
    "## Обучение методом градиентного спуска с несколькими выходами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "every-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#input\n",
    "toes = [8.5]\n",
    "wr = [0.65]\n",
    "fans = [1.2]\n",
    "input = [toes[0], wr[0], fans[0]]\n",
    "#goal prediction\n",
    "hurt = [0.1]\n",
    "win = [1]\n",
    "sad = [0.1]\n",
    "true = [hurt[0], win[0], sad[0]]\n",
    "#alpha\n",
    "alpha = 0.01\n",
    "#weights\n",
    "weights = [\n",
    "    [0.1,0.1,-.3],\n",
    "    [0.1,0.2,0.0],\n",
    "    [0.0, 1.3, 0.1]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "documented-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(input, weights):\n",
    "    assert(len(input) == len(weights))\n",
    "    out = [0,0,0]\n",
    "    for i in range(len(input)):\n",
    "        for j in range(len(input)):\n",
    "            out[i] += input[j] * weights[i][j]\n",
    "    return out\n",
    "def calibration(a, b):\n",
    "    assert(len(a) == len(b))\n",
    "    out = np.zeros((len(a),len(b)))\n",
    "    for i in range(len(a)):\n",
    "        for j in range(len(b)):\n",
    "            out[i][j] = a[i] * b[j]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "anonymous-diamond",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.555, 0.9800000000000001, 0.9650000000000001]\n",
      "[0.217788125, 0.9948224999999999, 0.32392687499999984]\n",
      "[0.13049240085937502, 0.9986596746875, 0.15796906976562497]\n",
      "[0.10789372027247063, 0.9996530232847265, 0.11500674293557611]\n",
      "[0.10204348683553588, 0.9999101764028336, 0.10388487057744723]\n",
      "[0.10052900765454936, 0.9999767469162835, 0.10100569587073659]\n",
      "[0.10013694685657143, 0.9999939803579528, 0.10026034951853695]\n",
      "[0.10003545211749498, 0.999998441665165, 0.10006739798161135]\n",
      "[0.10000917766691647, 0.9999995965860696, 0.10001744765248952]\n",
      "[0.10000237586852295, 0.9999998955662187, 0.10000451676103836]\n",
      "[0.10000061505296393, 0.9999999729647049, 0.10000116927651369]\n",
      "[0.10000015922183603, 0.999999993001238, 0.10000030269645752]\n",
      "[0.10000004121855277, 0.9999999981881955, 0.10000007836054543]\n",
      "[0.10000001067045289, 0.9999999995309691, 0.10000002028558634]\n",
      "[0.10000000276231352, 0.9999999998785796, 0.10000000525143109]\n",
      "[0.10000000071509396, 0.9999999999685673, 0.10000000135946423]\n",
      "[0.10000000018511984, 0.9999999999918627, 0.10000000035193134]\n",
      "[0.10000000004792292, 0.9999999999978935, 0.10000000009110634]\n",
      "[0.100000000012406, 0.9999999999994548, 0.10000000002358514]\n",
      "[0.10000000000321158, 0.9999999999998588, 0.10000000000610566]\n",
      "[0.10000000000083148, 0.9999999999999635, 0.1000000000015805]\n",
      "[0.1000000000002152, 0.9999999999999906, 0.10000000000040922]\n",
      "[0.10000000000005571, 0.9999999999999976, 0.1000000000001059]\n",
      "[0.10000000000001447, 0.9999999999999993, 0.10000000000002753]\n",
      "[0.10000000000000381, 0.9999999999999998, 0.10000000000000693]\n",
      "[0.10000000000000092, 0.9999999999999999, 0.10000000000000182]\n",
      "[0.10000000000000026, 1.0, 0.10000000000000057]\n",
      "[0.10000000000000009, 1.0, 0.10000000000000013]\n",
      "[0.10000000000000003, 1.0, 0.10000000000000002]\n",
      "[0.10000000000000003, 1.0, 0.10000000000000002]\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    pred = neural_network(input,weights)\n",
    "    print(pred)\n",
    "    delta = [0,0,0]\n",
    "    for i in range(len(delta)):\n",
    "        delta[i] = pred[i] - true[i]\n",
    "    weights_deltas = calibration(input, delta)\n",
    "    assert(len(weights_deltas) == len(weights))\n",
    "    for i in range(len(weights)):\n",
    "        for j in range(len(weights_deltas)):\n",
    "            weights[i][j] -= weights_deltas[j][i] * alpha\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-anthony",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-premium",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-cooler",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
